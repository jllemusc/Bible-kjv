{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZ2W/OT+BX2e4RwwL4NDfG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDTLtSfviuh_",
        "outputId": "e144e8d6-d663-46aa-ecb7-10e014ffa2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing textstat for readability analysis...\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 0: LIBRARYS NEEDED  ---\n",
        "# ==============================================================================\n",
        "\n",
        "# Colab / System Management (Required for environment setup)\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Data Science and Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "\n",
        "# NLP & Topic Modeling\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer # For Phase 6\n",
        "\n",
        "# Installation for textstat must happen before import as it's not a default Colab package\n",
        "print(\"Installing textstat for readability analysis...\")\n",
        "!pip install textstat -q\n",
        "import textstat # For Phase 6\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer # For Phase 9\n",
        "from sklearn.decomposition import LatentDirichletAllocation # For Phase 9\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud # For Phase 8\n",
        "from IPython.display import display, Markdown # FIX: Ensures the Markdown object is defined for displaying tables\n",
        "\n",
        "# --- NLTK Setup ---\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# --- Global Parameters ---\n",
        "DRIVE_PATH = '/content/drive/MyDrive'\n",
        "ZIP_FILE_NAME = 'Bible-kjv-master.zip'\n",
        "ZIP_FILE_PATH = os.path.join(DRIVE_PATH, ZIP_FILE_NAME)\n",
        "EXTRACT_DIR = '/content/bible_data'\n",
        "FINAL_DATA_DIR = '' # Will be set after successful unzipping\n",
        "\n",
        "# --- Helper Function: Load Text for Specific Books ---\n",
        "def load_book_texts(data_dir, book_names=None):\n",
        "    \"\"\"Loads raw text for specified books and returns a dictionary.\"\"\"\n",
        "    if not data_dir: return {}\n",
        "\n",
        "    book_texts = {}\n",
        "\n",
        "    # Generate expected filenames. If book_names is None, it loads all files.\n",
        "    json_files = [f + '.json' if not f.endswith('.json') else f for f in book_names] if book_names else [f for f in os.listdir(data_dir) if f.endswith('.json')]\n",
        "\n",
        "    for filename in json_files:\n",
        "        filepath = os.path.join(data_dir, filename)\n",
        "        full_book_text = []\n",
        "        book_name = filename.replace('.json', '')\n",
        "\n",
        "        try:\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                book_data = json.load(f)\n",
        "\n",
        "            book_info = book_data[0] if isinstance(book_data, list) and len(book_data) == 1 else book_data\n",
        "\n",
        "            chapters_list = book_info.get('chapters', [])\n",
        "            for chapter_obj in chapters_list:\n",
        "                for verse_obj in chapter_obj.get('verses', []):\n",
        "                    full_book_text.append(verse_obj.get('text', ''))\n",
        "\n",
        "            # The key should match the book name used in the DataFrame\n",
        "            if book_info.get('book'):\n",
        "                book_name = book_info.get('book')\n",
        "\n",
        "            book_texts[book_name] = \" \".join(full_book_text)\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return book_texts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 1: MOUNT GOOGLE DRIVE ---\n",
        "# ==============================================================================\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(f\"Drive mounted. Check files in: {DRIVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxZCM1o7j6eX",
        "outputId": "3b9c0ae4-9fb5-4292-f3d7-1ef68980aeae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive mounted. Check files in: /content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 2: UNZIP THE BIBLE DATA (CONFIRMED PATH) ---\n",
        "# ==============================================================================\n",
        "\n",
        "# Create a destination directory\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Unzipping {ZIP_FILE_PATH} to {EXTRACT_DIR}...\")\n",
        "try:\n",
        "    with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(EXTRACT_DIR)\n",
        "\n",
        "    temp_data_dir = os.path.join(EXTRACT_DIR, 'Bible-kjv-master')\n",
        "    test_file = os.path.join(temp_data_dir, 'Genesis.json')\n",
        "\n",
        "    if os.path.exists(test_file):\n",
        "        FINAL_DATA_DIR = temp_data_dir\n",
        "    else:\n",
        "        FINAL_DATA_DIR = EXTRACT_DIR\n",
        "\n",
        "    if os.path.exists(os.path.join(FINAL_DATA_DIR, 'Genesis.json')):\n",
        "        print(f\"âœ… Success! Individual book JSON files found in: {FINAL_DATA_DIR}\")\n",
        "    else:\n",
        "        print(f\"âŒ FATAL ERROR: Cannot confirm path to individual JSON files.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ FATAL ERROR during unzipping: {e}\")\n",
        "    FINAL_DATA_DIR = ''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT6PgpfMkTNL",
        "outputId": "a8eb861c-9a24-4436-a48b-2dd8f296b0bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping /content/drive/MyDrive/Bible-kjv-master.zip to /content/bible_data...\n",
            "âœ… Success! Individual book JSON files found in: /content/bible_data/Bible-kjv-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 3: ANALYSIS (Core Metrics: Word Count, Holiness Focus Score) ---\n",
        "# --- Using Robust REGEX for Holy/Holiness Counting ---\n",
        "# ==============================================================================\n",
        "\n",
        "def create_comprehensive_analysis_table_fixed(data_dir):\n",
        "    \"\"\"Calculates all metrics using robust regex for accurate word and theme counts.\"\"\"\n",
        "    if not data_dir: return pd.DataFrame()\n",
        "    data = []\n",
        "\n",
        "    try:\n",
        "        json_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.json')])\n",
        "    except FileNotFoundError:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"\\n--- PHASE 5: Robust REGEX Counting ---\")\n",
        "    print(f\"Found {len(json_files)} book files. Calculating all metrics...\")\n",
        "\n",
        "    # Robust patterns\n",
        "    HOLY_PATTERN = re.compile(r'\\b(holy|holiness)\\b') # Catching both words robustly\n",
        "\n",
        "    for filename in json_files:\n",
        "        filepath = os.path.join(data_dir, filename)\n",
        "        full_book_text = []\n",
        "\n",
        "        try:\n",
        "            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                book_data = json.load(f)\n",
        "\n",
        "            book_info = book_data[0] if isinstance(book_data, list) and len(book_data) == 1 else book_data\n",
        "\n",
        "            chapters_list = book_info.get('chapters', [])\n",
        "            for chapter_obj in chapters_list:\n",
        "                for verse_obj in chapter_obj.get('verses', []):\n",
        "                    full_book_text.append(verse_obj.get('text', ''))\n",
        "\n",
        "            book_text = \" \".join(full_book_text).lower()\n",
        "\n",
        "            # --- CALCULATION 1: Robust Total Word Count ---\n",
        "            total_words = len(book_text.split()) # Simple whitespace split is standard for word count\n",
        "\n",
        "            # --- CALCULATION 2: Robust Holiness Focus Score (Raw Count) ---\n",
        "            holy_count = len(HOLY_PATTERN.findall(book_text))\n",
        "\n",
        "            if total_words > 0:\n",
        "                book_name = book_info.get('book', filename.replace('.json', ''))\n",
        "\n",
        "                data.append({\n",
        "                    'Book': book_name,\n",
        "                    'Total Words': total_words,\n",
        "                    'Holiness Focus Score': holy_count,\n",
        "                    'Holiness Intensity': (holy_count / total_words) * 1000 # Count per 1000 words\n",
        "                })\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    df_sorted = df.sort_values(by='Holiness Intensity', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # --- ADDED: Display Table for Phase 3 ---\n",
        "    print(\"\\n## ðŸ“Š PHASE 5: Holiness Intensity Ranking (Top 10 Books)\")\n",
        "    display_df = df_sorted[['Book', 'Total Words', 'Holiness Focus Score', 'Holiness Intensity']].head(30)\n",
        "\n",
        "    # ðŸŒŸ NEW DEBUG STEP: Print raw DataFrame to guarantee output visibility\n",
        "    print(\"--- Raw DataFrame Preview (Confirming Data Exists) ---\")\n",
        "    print(display_df)\n",
        "    print(\"-------------------------------------------------------\")\n",
        "\n",
        "    display(Markdown(display_df.to_markdown(index=False, floatfmt=\".2f\")))\n",
        "    # --- END ADDITION ---\n",
        "\n",
        "    print(\"âœ… Core metrics calculated. Proceeding to Phase 4.\")\n",
        "\n",
        "    return df_sorted"
      ],
      "metadata": {
        "id": "vfj0_D4L34O0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTION PHASE 3 ---\n",
        "FINAL_ANALYSIS_DF = pd.DataFrame()\n",
        "if FINAL_DATA_DIR:\n",
        "    FINAL_ANALYSIS_DF = create_comprehensive_analysis_table_fixed(FINAL_DATA_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f7EKoQ8o7VmL",
        "outputId": "6a84a77d-ec08-4b72-ce90-0991c5d9d62c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PHASE 5: Robust REGEX Counting ---\n",
            "Found 67 book files. Calculating all metrics...\n",
            "\n",
            "## ðŸ“Š PHASE 5: Holiness Intensity Ranking (Top 10 Books)\n",
            "--- Raw DataFrame Preview (Confirming Data Exists) ---\n",
            "               Book  Total Words  Holiness Focus Score  Holiness Intensity\n",
            "0           2 Peter         1553                     6            3.863490\n",
            "1         Leviticus        24540                    94            3.830481\n",
            "2   1 Thessalonians         1837                     7            3.810561\n",
            "3             Titus          896                     3            3.348214\n",
            "4              Jude          608                     2            3.289474\n",
            "5           1 Peter         2476                     8            3.231018\n",
            "6           Obadiah          669                     2            2.989537\n",
            "7         Ephesians         3022                     7            2.316347\n",
            "8              Acts        24245                    53            2.186018\n",
            "9          Habakkuk         1475                     3            2.033898\n",
            "10        2 Timothy         1666                     3            1.800720\n",
            "11           Exodus        32684                    58            1.774569\n",
            "12           Haggai         1130                     2            1.769912\n",
            "13          Hebrews         6897                    12            1.739887\n",
            "14           Romans         9422                    16            1.698153\n",
            "15           Isaiah        37040                    61            1.646868\n",
            "16            Jonah         1320                     2            1.515152\n",
            "17             Joel         2033                     3            1.475652\n",
            "18           Daniel        11602                    17            1.465265\n",
            "19       Revelation        11995                    16            1.333889\n",
            "20          Ezekiel        39402                    49            1.243592\n",
            "21           Psalms        42685                    50            1.171372\n",
            "22       Colossians         1979                     2            1.010611\n",
            "23         Nehemiah        10480                    10            0.954198\n",
            "24        1 Timothy         2244                     2            0.891266\n",
            "25          Numbers        32893                    29            0.881647\n",
            "26    1 Corinthians         9462                     8            0.845487\n",
            "27           1 John         2516                     2            0.794913\n",
            "28        Zechariah         6443                     5            0.776036\n",
            "29             Luke        25939                    20            0.771040\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Book            |   Total Words |   Holiness Focus Score |   Holiness Intensity |\n|:----------------|--------------:|-----------------------:|---------------------:|\n| 2 Peter         |          1553 |                      6 |                 3.86 |\n| Leviticus       |         24540 |                     94 |                 3.83 |\n| 1 Thessalonians |          1837 |                      7 |                 3.81 |\n| Titus           |           896 |                      3 |                 3.35 |\n| Jude            |           608 |                      2 |                 3.29 |\n| 1 Peter         |          2476 |                      8 |                 3.23 |\n| Obadiah         |           669 |                      2 |                 2.99 |\n| Ephesians       |          3022 |                      7 |                 2.32 |\n| Acts            |         24245 |                     53 |                 2.19 |\n| Habakkuk        |          1475 |                      3 |                 2.03 |\n| 2 Timothy       |          1666 |                      3 |                 1.80 |\n| Exodus          |         32684 |                     58 |                 1.77 |\n| Haggai          |          1130 |                      2 |                 1.77 |\n| Hebrews         |          6897 |                     12 |                 1.74 |\n| Romans          |          9422 |                     16 |                 1.70 |\n| Isaiah          |         37040 |                     61 |                 1.65 |\n| Jonah           |          1320 |                      2 |                 1.52 |\n| Joel            |          2033 |                      3 |                 1.48 |\n| Daniel          |         11602 |                     17 |                 1.47 |\n| Revelation      |         11995 |                     16 |                 1.33 |\n| Ezekiel         |         39402 |                     49 |                 1.24 |\n| Psalms          |         42685 |                     50 |                 1.17 |\n| Colossians      |          1979 |                      2 |                 1.01 |\n| Nehemiah        |         10480 |                     10 |                 0.95 |\n| 1 Timothy       |          2244 |                      2 |                 0.89 |\n| Numbers         |         32893 |                     29 |                 0.88 |\n| 1 Corinthians   |          9462 |                      8 |                 0.85 |\n| 1 John          |          2516 |                      2 |                 0.79 |\n| Zechariah       |          6443 |                      5 |                 0.78 |\n| Luke            |         25939 |                     20 |                 0.77 |"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Core metrics calculated. Proceeding to Phase 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 4: SENTIMENT & CONTRAST ANALYSIS (Righteousness, Sentiment) ---\n",
        "# ==============================================================================\n",
        "\n",
        "def run_sentiment_analysis(df_holiness, data_dir):\n",
        "    \"\"\"Calculates sentiment scores and 'Righteous' contrast for each book.\"\"\"\n",
        "    if df_holiness.empty or not data_dir: return df_holiness\n",
        "\n",
        "    print(\"\\n--- PHASE 4: Running Sentiment Analysis and Righteousness Contrast ---\")\n",
        "\n",
        "    book_names = df_holiness['Book'].tolist()\n",
        "    # Load all book texts at once for efficiency\n",
        "    book_texts_dict = load_book_texts(data_dir, book_names)\n",
        "\n",
        "    sentiment_data = []\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    RIGHTEOUS_PATTERN = re.compile(r'\\b(righteous|righteousness)\\b') # Robustly match both forms\n",
        "\n",
        "    for book_name, text in book_texts_dict.items():\n",
        "        # Get total words from the main DF for accurate normalization\n",
        "        total_words = df_holiness[df_holiness['Book'] == book_name]['Total Words'].iloc[0]\n",
        "\n",
        "        if not text or total_words == 0: continue\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # 1. Sentiment (VADER)\n",
        "        vs = sia.polarity_scores(text)\n",
        "\n",
        "        # 2. Thematic Contrast: 'Righteous' count & intensity\n",
        "        righteous_count = len(RIGHTEOUS_PATTERN.findall(text_lower))\n",
        "        righteous_intensity = (righteous_count / total_words) * 1000 if total_words > 0 else 0\n",
        "\n",
        "        sentiment_data.append({\n",
        "            'Book': book_name,\n",
        "            'Sentiment (Compound)': vs['compound'],\n",
        "            'Righteous Count (Raw)': righteous_count,\n",
        "            'Righteous Intensity (Per 1000 Words)': righteous_intensity\n",
        "        })\n",
        "\n",
        "    df_sentiment = pd.DataFrame(sentiment_data)\n",
        "\n",
        "    # Merge with the comprehensive analysis table (Phase 5 output)\n",
        "    df_final = pd.merge(df_holiness, df_sentiment, on='Book', how='left')\n",
        "\n",
        "    # Re-sort to maintain order after merge\n",
        "    df_final = df_final.sort_values(by='Holiness Intensity', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"âœ… Sentiment and Righteousness contrast complete.\")\n",
        "\n",
        "    # Print the resulting table (Top 10 for review)\n",
        "    print(\"\\n## ðŸ“š PHASE 4: Comprehensive Book Analysis - Top 10 Metrics (Includes Sentiment)\")\n",
        "    display(Markdown(df_final.head(10).to_markdown(index=False, floatfmt=\".4f\")))\n",
        "\n",
        "    # NEW DEBUG STEP: Print columns to confirm names match for Phase 7\n",
        "    print(f\"--- Phase 4 Final DataFrame Columns Confirmation ---\")\n",
        "    print(df_final.columns.tolist())\n",
        "    print(\"----------------------------------------------------\")\n",
        "\n",
        "    return df_final"
      ],
      "metadata": {
        "id": "42BNDha5lbi4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTION PHASE 4 ---\n",
        "if not FINAL_ANALYSIS_DF.empty:\n",
        "    FINAL_ANALYSIS_DF = run_sentiment_analysis(FINAL_ANALYSIS_DF, FINAL_DATA_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "SDfLFN-WlgBz",
        "outputId": "81263adb-a528-4a86-e822-164df78c0ed2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PHASE 4: Running Sentiment Analysis and Righteousness Contrast ---\n",
            "âœ… Sentiment and Righteousness contrast complete.\n",
            "\n",
            "## ðŸ“š PHASE 4: Comprehensive Book Analysis - Top 10 Metrics (Includes Sentiment)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Book            |   Total Words |   Holiness Focus Score |   Holiness Intensity |   Sentiment (Compound) |   Righteous Count (Raw) |   Righteous Intensity (Per 1000 Words) |\n|:----------------|--------------:|-----------------------:|---------------------:|-----------------------:|------------------------:|---------------------------------------:|\n| 2 Peter         |          1553 |                      6 |               3.8635 |               nan      |                nan      |                               nan      |\n| Leviticus       |         24540 |                     94 |               3.8305 |                -0.9999 |                  1.0000 |                                 0.0407 |\n| 1 Thessalonians |          1837 |                      7 |               3.8106 |               nan      |                nan      |                               nan      |\n| Titus           |           896 |                      3 |               3.3482 |                 0.9995 |                  1.0000 |                                 1.1161 |\n| Jude            |           608 |                      2 |               3.2895 |                 0.9935 |                  0.0000 |                                 0.0000 |\n| 1 Peter         |          2476 |                      8 |               3.2310 |               nan      |                nan      |                               nan      |\n| Obadiah         |           669 |                      2 |               2.9895 |                -0.9571 |                  0.0000 |                                 0.0000 |\n| Ephesians       |          3022 |                      7 |               2.3163 |                 0.9999 |                  3.0000 |                                 0.9927 |\n| Acts            |         24245 |                     53 |               2.1860 |                 1.0000 |                  4.0000 |                                 0.1650 |\n| Habakkuk        |          1475 |                      3 |               2.0339 |                -0.9983 |                  2.0000 |                                 1.3559 |"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Phase 4 Final DataFrame Columns Confirmation ---\n",
            "['Book', 'Total Words', 'Holiness Focus Score', 'Holiness Intensity', 'Sentiment (Compound)', 'Righteous Count (Raw)', 'Righteous Intensity (Per 1000 Words)']\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 5: PLOT GENERATION (ORGANIZED AS REQUESTED) ---\n",
        "# 1. Holiness Intensity Ranking (Vertical, Descending, Top 30)\n",
        "# 2. Holiness vs. Righteousness Comparison (Top 15)\n",
        "# 3. Sentiment Compound Score (Top 10)\n",
        "# ==============================================================================\n",
        "\n",
        "def create_initial_analysis_plots(df_data):\n",
        "    \"\"\"Generates the requested plots in the specified order and format.\"\"\"\n",
        "    print(\"\\n--- PHASE 5: Generating Reorganized Analysis Plots ---\")\n",
        "\n",
        "    # ðŸŒŸ NEW ROBUSTNESS CHECK: Verify required columns exist before proceeding\n",
        "    required_cols = ['Holiness Intensity', 'Righteous Intensity (Per 1000 Words)', 'Sentiment (Compound)']\n",
        "\n",
        "    if df_data.empty or not all(col in df_data.columns for col in required_cols):\n",
        "        print(\"âŒ FAILED TO PLOT: Cannot proceed with Phase 7 plots. The required data columns (Holiness Intensity, Righteous Intensity, or Sentiment) are missing.\")\n",
        "        if not df_data.empty:\n",
        "            print(f\"Found columns: {df_data.columns.tolist()}\")\n",
        "        print(\"ðŸ’¡ Action required: Check the output of Phase 6 to ensure it successfully loaded data and merged the 'Righteousness' and 'Sentiment' metrics.\")\n",
        "        return\n",
        "\n",
        "    # Select the top 30 books for the main plot\n",
        "    df_plot_top30 = df_data.head(30).copy()\n",
        "\n",
        "    # Select the top 15 books for the comparison plot\n",
        "    df_plot_top15 = df_data.head(15).copy()\n",
        "\n",
        "    # Convert necessary columns to numeric for plotting (This is where the KeyError occurred previously)\n",
        "    df_plot_top30['Holiness Intensity_Num'] = df_plot_top30['Holiness Intensity'].astype(float)\n",
        "    df_plot_top15['Holiness Intensity_Num'] = df_plot_top15['Holiness Intensity'].astype(float)\n",
        "\n",
        "    # ERROR FIX: This line will now only execute if the column check passed above\n",
        "    df_plot_top15['Righteous Intensity_Num'] = df_plot_top15['Righteous Intensity (Per 1000 Words)'].astype(float)\n",
        "    df_plot_top15['Sentiment (Compound)_Num'] = df_plot_top15['Sentiment (Compound)'].astype(float)\n",
        "\n",
        "\n",
        "    # --- 1. PLOT: Holiness Intensity Ranking (Vertical, Descending) - TOP 30 ---\n",
        "    fig, ax = plt.subplots(figsize=(20, 8)) # Increased size to accommodate 30 books\n",
        "\n",
        "    books = df_plot_top30['Book']\n",
        "    intensity = df_plot_top30['Holiness Intensity_Num']\n",
        "\n",
        "    # Create a vertical bar chart\n",
        "    ax.bar(books, intensity, color='#8B4513')\n",
        "\n",
        "    ax.set_title('1. Holiness Intensity Map (Mentions of \"Holy/Holiness\" per 1000 Words) - Top 30 Books', fontsize=18, weight='bold')\n",
        "    ax.set_xlabel('Book of the Bible (Highest Intensity on Left)', fontsize=14)\n",
        "    ax.set_ylabel('Holiness Intensity (Count per 1000 Words)', fontsize=14)\n",
        "\n",
        "    ax.set_xticklabels(books, rotation=60, ha=\"right\", fontsize=10) # Rotate and shrink font for 30 labels\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Holiness_Intensity_Ranking_Vertical_Map_Top30.png')\n",
        "    print(\"âœ… Saved 1. Holiness Intensity Ranking Bar Chart (Vertical, Descending, Top 30).\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    # --- 2. PLOT: Holiness Intensity vs. Righteous Intensity (Normalized Bar Chart - Top 15) ---\n",
        "    fig, ax = plt.subplots(figsize=(18, 8))\n",
        "\n",
        "    width = 0.35\n",
        "    x = np.arange(len(df_plot_top15['Book']))\n",
        "\n",
        "    # Holiness Intensity (Per 1000 Words)\n",
        "    ax.bar(x - width/2, df_plot_top15['Holiness Intensity_Num'], width, label='Holy/Holiness Intensity', color='#4c72b0', alpha=0.9)\n",
        "\n",
        "    # Righteous Intensity (Per 1000 Words)\n",
        "    ax.bar(x + width/2, df_plot_top15['Righteous Intensity_Num'], width, label='Righteousness Intensity', color='#c44e52', alpha=0.9)\n",
        "\n",
        "    ax.set_ylabel('Intensity (Mentions per 1000 Words)', fontsize=14)\n",
        "    ax.set_title('2. Top 15 Books: Holy/Holiness vs. Righteousness Intensity Comparison', fontsize=16, weight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(df_plot_top15['Book'], rotation=45, ha=\"right\")\n",
        "    ax.legend(loc='upper right')\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Holiness_Righteousness_Intensity_Comparison.png')\n",
        "    print(\"âœ… Saved 2. Holy/Righteousness Intensity Comparison Bar Chart (Top 15).\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    # --- 3. PLOT: Sentiment (VADER Compound Score) for Top 10 Books ---\n",
        "    df_plot_top10 = df_plot_top15.head(10).copy() # Filter to top 10 as requested\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 7))\n",
        "\n",
        "    sentiment = df_plot_top10['Sentiment (Compound)_Num']\n",
        "\n",
        "    # Color the bars based on the score\n",
        "    colors = ['#4daf4a' if s > 0.05 else ('#e41a1c' if s < -0.05 else '#ff7f00') for s in sentiment]\n",
        "\n",
        "    ax.bar(df_plot_top10['Book'], sentiment, color=colors, alpha=0.8)\n",
        "\n",
        "    ax.axhline(0, color='gray', linestyle='--', linewidth=1.5) # Add zero line for reference\n",
        "\n",
        "    ax.set_title('3. Top 10 Books: VADER Compound Sentiment Score', fontsize=16, weight='bold')\n",
        "    ax.set_xlabel('Book', fontsize=12)\n",
        "    ax.set_ylabel('VADER Compound Sentiment Score', fontsize=12)\n",
        "    ax.set_xticklabels(df_plot_top10['Book'], rotation=45, ha=\"right\")\n",
        "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Sentiment_Compound_Top10_Bar_Chart.png')\n",
        "    print(\"âœ… Saved 3. Sentiment Compound Score Bar Chart (Top 10).\")\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "gKdoNLHEp2N3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTION PHASE 5 ---\n",
        "if not FINAL_ANALYSIS_DF.empty:\n",
        "    create_initial_analysis_plots(FINAL_ANALYSIS_DF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbwUU1iPvTQv",
        "outputId": "55e753c3-7041-4fee-993b-0f545f444405"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PHASE 5: Generating Reorganized Analysis Plots ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3165597962.py:50: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(books, rotation=60, ha=\"right\", fontsize=10) # Rotate and shrink font for 30 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved 1. Holiness Intensity Ranking Bar Chart (Vertical, Descending, Top 30).\n",
            "âœ… Saved 2. Holy/Righteousness Intensity Comparison Bar Chart (Top 15).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3165597962.py:100: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(df_plot_top10['Book'], rotation=45, ha=\"right\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved 3. Sentiment Compound Score Bar Chart (Top 10).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 6: BUBBLE PLOT IN THE 15 PRINCIPLE BOOKS (NEW) ---\n",
        "# Visualizing Thematic Intensity (Mock) vs. Topic (Size=Total Words)\n",
        "# ==============================================================================\n",
        "\n",
        "def create_thematic_bubble_plot(df_data, data_dir):\n",
        "    \"\"\"Generates a thematic bubble plot for the top 15 books.\"\"\"\n",
        "    if df_data.empty:\n",
        "        print(\"âŒ Cannot run Phase 8: Input DataFrame is empty.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n--- PHASE 6: Generating Thematic Bubble Plot Visualization ---\")\n",
        "\n",
        "    # 1. Prepare Data (using REAL data and filtering for top 15)\n",
        "    # Filter down to the top 15 books by Holiness Intensity\n",
        "    df_top_15 = df_data.sort_values(by='Holiness Intensity', ascending=False).head(15).copy()\n",
        "\n",
        "    if df_top_15.empty:\n",
        "        print(\"âŒ Cannot run Phase 8: Top 15 books list is empty after filtering.\")\n",
        "        return\n",
        "\n",
        "    # Dynamically generate the required data structures\n",
        "    top_15_books = df_top_15['Book'].tolist()\n",
        "    word_counts_map = dict(zip(df_top_15['Book'], df_top_15['Total Words']))\n",
        "\n",
        "    # 2. Topics (8 Topics - Static, as per original mock script)\n",
        "    # NOTE: These are the exact topic titles requested by the user for this plot.\n",
        "    topics = [\n",
        "        'End Times', 'Prophecy/Judgment', 'Apostolic Teaching',\n",
        "        'Salvation/Grace', 'History/Narrative', 'Kingdom/Rule',\n",
        "        'Purity/Ritual', 'Mission/Evangelism'\n",
        "    ]\n",
        "    num_topics = len(topics)\n",
        "\n",
        "    # 3. Bubble Size and Mock Data Generation (Using REAL Word Counts)\n",
        "    word_counts = np.array([word_counts_map[book] for book in top_15_books])\n",
        "\n",
        "    # Normalize to a visible range (50 to 5050)\n",
        "    bubble_size = (word_counts / word_counts.max()) * 5000 + 50\n",
        "\n",
        "    mock_data = []\n",
        "\n",
        "    for book in top_15_books:\n",
        "        topic_id = 0\n",
        "        intensity_value = random.uniform(0.5, 1.5)\n",
        "\n",
        "        # Logic to assign a primary topic and relevant intensity (same logic as user's original mock script)\n",
        "        if book in ['2 Peter', '1 Thessalonians', 'Titus', '2 Timothy', '1 Peter', 'Ephesians']:\n",
        "            # Apostolic Teaching (2), Salvation/Grace (3), Mission/Evangelism (7)\n",
        "            topic_id = random.choice([2, 3, 7])\n",
        "            intensity_value = random.uniform(3.8, 5.0)\n",
        "        elif book in ['Jude', 'Obadiah', 'Habakkuk', 'Jonah']:\n",
        "            # End Times (0), Prophecy/Judgment (1)\n",
        "            topic_id = random.choice([0, 1])\n",
        "            intensity_value = random.uniform(3.0, 4.5)\n",
        "        elif book == 'Leviticus':\n",
        "            # Purity/Ritual (6)\n",
        "            topic_id = 6\n",
        "            intensity_value = random.uniform(4.5, 5.0)\n",
        "        elif book == 'Acts':\n",
        "            # History/Narrative (4), Mission/Evangelism (7)\n",
        "            topic_id = random.choice([4, 7])\n",
        "            intensity_value = random.uniform(2.5, 4.0)\n",
        "        elif book in ['Isaiah', 'Daniel', 'Hebrews']:\n",
        "            # Kingdom/Rule (5), Prophecy (1), Salvation/Grace (3)\n",
        "            topic_id = random.choice([5, 1, 3])\n",
        "            intensity_value = random.uniform(2.5, 4.0)\n",
        "        else:\n",
        "            # Fallback for any book not in the original hardcoded list\n",
        "            topic_id = random.randint(0, num_topics - 1)\n",
        "            intensity_value = random.uniform(1.0, 3.0)\n",
        "\n",
        "        mock_data.append({\n",
        "            'Book': book,\n",
        "            'Topic_ID': topic_id,\n",
        "            'Intensity': intensity_value,\n",
        "            'Bubble_Size': bubble_size[top_15_books.index(book)],\n",
        "            'Topic_Name': topics[topic_id]\n",
        "        })\n",
        "\n",
        "    df_bubble = pd.DataFrame(mock_data)\n",
        "\n",
        "    # 4. Plotting\n",
        "    plt.figure(figsize=(18, 10))\n",
        "\n",
        "    # Map Topic_ID to a discrete color palette (using 8 colors)\n",
        "    cmap = plt.cm.get_cmap('tab10', num_topics)\n",
        "\n",
        "    # Create the scatter plot (bubble plot)\n",
        "    scatter = plt.scatter(\n",
        "        df_bubble['Topic_ID'],\n",
        "        df_bubble['Intensity'],\n",
        "        s=df_bubble['Bubble_Size'],\n",
        "        c=df_bubble['Topic_ID'],\n",
        "        cmap=cmap,\n",
        "        alpha=0.7,\n",
        "        edgecolors=\"k\",\n",
        "        linewidth=1.0\n",
        "    )\n",
        "\n",
        "    # 1. Label the bubbles with the book name\n",
        "    for i, row in df_bubble.iterrows():\n",
        "        plt.annotate(\n",
        "            row['Book'],\n",
        "            (row['Topic_ID'], row['Intensity']),\n",
        "            textcoords=\"offset points\",\n",
        "            xytext=(0, 5),\n",
        "            ha='center',\n",
        "            fontsize=9,\n",
        "            weight='bold'\n",
        "        )\n",
        "\n",
        "    # 2. Set the X-axis labels to the Topic Names\n",
        "    plt.xticks(\n",
        "        range(num_topics),\n",
        "        topics,\n",
        "        rotation=60,\n",
        "        ha='right',\n",
        "        fontsize=11\n",
        "    )\n",
        "    plt.yticks(fontsize=11)\n",
        "\n",
        "    # 3. Set Plot Titles and Labels\n",
        "    plt.title(\n",
        "        'PHASE 8: Thematic Bubble Plot (Top 15 Holiness Books by Topic & Conceptual Intensity)',\n",
        "        fontsize=18,\n",
        "        weight='bold'\n",
        "    )\n",
        "    plt.xlabel('Primary Thematic Topic Area (Color-Coded)', fontsize=14)\n",
        "    plt.ylabel('Thematic Intensity / Relevance (Conceptual Score 0-5)', fontsize=14)\n",
        "\n",
        "    # 4. Add Legend for Bubble Size (Word Count)\n",
        "    word_counts_sorted = sorted(word_counts_map.values())\n",
        "\n",
        "    if len(word_counts_sorted) >= 3:\n",
        "        legend_sizes_values = [\n",
        "            word_counts_sorted[0],                 # Smallest\n",
        "            word_counts_sorted[len(word_counts_sorted)//2], # Median\n",
        "            word_counts_sorted[-1]                 # Largest\n",
        "        ]\n",
        "    else:\n",
        "        legend_sizes_values = word_counts_sorted\n",
        "\n",
        "    size_handles = [\n",
        "        (s / word_counts.max()) * 5000 + 50\n",
        "        for s in legend_sizes_values\n",
        "    ]\n",
        "\n",
        "    plt.legend(\n",
        "        [plt.scatter([], [], s=s, c='gray', alpha=0.7, edgecolors=\"k\", linewidth=1.0) for s in size_handles],\n",
        "        [f'{s:,} words' for s in legend_sizes_values],\n",
        "        loc=\"upper right\",\n",
        "        title=\"Relative Book Length (Word Count)\",\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plot_filename = 'Thematic_Bubble_Plot.png'\n",
        "    plt.savefig(plot_filename)\n",
        "    print(f\"âœ… Saved Thematic Bubble Plot to {plot_filename}\")\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "0wiyVLrsl4ni"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTION PHASE 6 ---\n",
        "if not FINAL_ANALYSIS_DF.empty:\n",
        "    create_thematic_bubble_plot(FINAL_ANALYSIS_DF, FINAL_DATA_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJzEsxDimAqa",
        "outputId": "639ef140-57b4-42c2-9fc2-7f5760edd623"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PHASE 6: Generating Thematic Bubble Plot Visualization ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1031664252.py:87: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  cmap = plt.cm.get_cmap('tab10', num_topics)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved Thematic Bubble Plot to Thematic_Bubble_Plot.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- PHASE 7: LDA Topic Modeling on Top 15 \"Holiness\" Books (For completeness) ---\n",
        "# ==============================================================================\n",
        "\n",
        "def run_lda_topic_modeling(data_dir, df_holiness):\n",
        "    \"\"\"Performs LDA on the corpus of the top 15 books and generates a separate Word Cloud for each topic.\"\"\"\n",
        "    if df_holiness.empty or not data_dir: return\n",
        "\n",
        "    print(\"\\n--- PHASE 7: LDA Topic Modeling and Word Clouds ---\")\n",
        "\n",
        "    # 1. Define Top 15 Books\n",
        "    df_top_15 = df_holiness.head(15).copy()\n",
        "    top_15_books = df_top_15['Book'].tolist()\n",
        "\n",
        "    # 2. Load Corpus\n",
        "    book_texts_dict = load_book_texts(data_dir, top_15_books)\n",
        "    corpus = list(book_texts_dict.values())\n",
        "\n",
        "    if not corpus:\n",
        "        print(\"âŒ Cannot proceed with LDA: Corpus is empty.\")\n",
        "        return\n",
        "\n",
        "    # 3. Preprocessing\n",
        "    try:\n",
        "        # Check if stopwords are available locally\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "    except Exception:\n",
        "        stop_words = set()\n",
        "\n",
        "    custom_stopwords = ['thee', 'thou', 'thy', 'hath', 'doth', 'saying', 'said', 'shall', 'unto', 'verily', 'come', 'came', 'man', 'lord', 'god', 'hallowed', 'therefore', 'also', 'thus']\n",
        "    stop_words.update(custom_stopwords)\n",
        "\n",
        "    processed_corpus = []\n",
        "    for text in corpus:\n",
        "        text = text.lower()\n",
        "        words = re.findall(r'\\b[a-z]{3,}\\b', text)\n",
        "        filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
        "        processed_corpus.append(\" \".join(filtered_words))\n",
        "\n",
        "    # 4. Create Document-Term Matrix (DTM)\n",
        "    n_topics = 8\n",
        "    n_top_words = 30\n",
        "\n",
        "    vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words=None)\n",
        "    dtm = vectorizer.fit_transform(processed_corpus)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # 5. LDA Model\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=n_topics,\n",
        "        random_state=42\n",
        "    )\n",
        "    lda.fit(dtm)\n",
        "\n",
        "    print(f\"âœ… LDA Model trained on {len(corpus)} documents with {n_topics} topics.\")\n",
        "\n",
        "    # 6. Visualization (Word Clouds)\n",
        "    # Using the static topic titles provided by the user for consistency with Phase 8\n",
        "    topic_titles = [\n",
        "        'End Times',\n",
        "        'Prophecy/Judgment',\n",
        "        'Apostolic Teaching',\n",
        "        'Salvation/Grace',\n",
        "        'History/Narrative',\n",
        "        'Kingdom/Rule',\n",
        "        'Purity/Ritual',\n",
        "        'Mission/Evangelism'\n",
        "    ]\n",
        "\n",
        "    colormaps = ['viridis', 'plasma', 'inferno', 'magma', 'cividis', 'tab10', 'Pastel1', 'Dark2']\n",
        "\n",
        "    for i, topic in enumerate(lda.components_):\n",
        "        freq = {feature_names[j]: topic[j] for j in topic.argsort()[:-n_top_words - 1:-1]}\n",
        "\n",
        "        wc = WordCloud(\n",
        "            background_color='white',\n",
        "            width=800,\n",
        "            height=600,\n",
        "            colormap=colormaps[i % len(colormaps)],\n",
        "            prefer_horizontal=0.9,\n",
        "            min_font_size=8\n",
        "        ).generate_from_frequencies(freq)\n",
        "\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.imshow(wc, interpolation='bilinear')\n",
        "        plt.axis('off')\n",
        "\n",
        "        title = topic_titles[i] if i < len(topic_titles) else f'Unnamed Topic {i+1}'\n",
        "        plt.title(f\"PHASE 7: Topic {i+1}: {title}\", fontsize=16, weight='bold')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        filename = f\"Topic_{i+1}_{title.replace('&', 'and').replace(' ', '_').replace(',', '').replace('/', 'or')}.png\"\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    print(\"âœ… Generated Word Clouds for all 8 LDA topics.\")"
      ],
      "metadata": {
        "id": "AfoWpG8onnQA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUTION PHASE 7 ---\n",
        "if not FINAL_ANALYSIS_DF.empty:\n",
        "    run_lda_topic_modeling(FINAL_DATA_DIR, FINAL_ANALYSIS_DF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IS6hrQmnunf",
        "outputId": "9dfa528e-4a44-4b12-8f5f-aea301fae677"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PHASE 7: LDA Topic Modeling and Word Clouds ---\n",
            "âœ… LDA Model trained on 11 documents with 8 topics.\n",
            "âœ… Generated Word Clouds for all 8 LDA topics.\n"
          ]
        }
      ]
    }
  ]
}